--- postfix-2.11/src/global/mkmap_lmdb.c	2013/10/01 21:03:36	1.1
+++ postfix-2.11/src/global/mkmap_lmdb.c	2013/10/01 21:04:00
@@ -98,18 +98,6 @@
     dict_lmdb_map_size = var_lmdb_map_size;
 
     /*
-     * XXX Why is this not set in mail_params.c (with proper #ifdefs)?
-     * 
-     * Set the max number of concurrent readers per table. This is the
-     * maximum number of postfix processes, plus some extra for CLI users.
-     * 
-     * XXX Postfix uses asynchronous or blocking I/O with single-threaded
-     * processes so this limit will never be reached, assuming that the limit
-     * is a per-client property, not a shared database property.
-     */
-    dict_lmdb_max_readers = var_proc_limit * 2 + 16;
-
-    /*
      * Fill in the generic members.
      */
     mkmap->open = dict_lmdb_open;
--- postfix-2.11/src/util/dict_lmdb.c	2013/10/01 21:00:27	1.1
+++ postfix-2.11/src/util/dict_lmdb.c	2013/10/01 20:59:38
@@ -134,13 +134,7 @@
 #define DICT_LMDB_BULK_RETRY_LIMIT \
 	(2 * sizeof(size_t) * CHAR_BIT)	/* Retries per bulk-mode transaction */
 
- /*
-  * XXX Should dict_lmdb_max_readers be configurable? Is this a per-database
-  * property? Per-process? Does it need to be the same for all processes?
-  */
 size_t  dict_lmdb_map_size = 8192;	/* Minimum size without SIGSEGV */
-unsigned int dict_lmdb_max_readers = 216;	/* 200 postfix processes,
-						 * plus some extra */
 
 /* #define msg_verbose 1 */
 
@@ -539,6 +533,13 @@
     }
 
     /*
+     * Acquire a shared lock.
+     */
+    if ((dict->flags & DICT_FLAG_LOCK)
+	&& myflock(dict->lock_fd, INTERNAL_LOCK, MYFLOCK_OP_SHARED) < 0)
+	msg_fatal("%s: lock dictionary: %m", dict->name);
+
+    /*
      * See if this LMDB file was written with one null byte appended to key
      * and value.
      */
@@ -575,6 +576,14 @@
 		      mdb_strerror(status));
 	}
     }
+
+    /*
+     * Release the shared lock.
+     */
+    if ((dict->flags & DICT_FLAG_LOCK)
+	&& myflock(dict->lock_fd, INTERNAL_LOCK, MYFLOCK_OP_NONE) < 0)
+	msg_fatal("%s: unlock dictionary: %m", dict->name);
+
     return (result);
 }
 
@@ -633,6 +642,13 @@
     }
 
     /*
+     * Acquire an exclusive lock.
+     */
+    if ((dict->flags & DICT_FLAG_LOCK)
+	&& myflock(dict->lock_fd, INTERNAL_LOCK, MYFLOCK_OP_EXCLUSIVE) < 0)
+	msg_fatal("%s: lock dictionary: %m", dict->name);
+
+    /*
      * Do the update.
      */
     status = dict_lmdb_put(dict_lmdb, &mdb_key, &mdb_value,
@@ -653,6 +669,14 @@
 		      mdb_strerror(status));
 	}
     }
+
+    /*
+     * Release the exclusive lock.
+     */
+    if ((dict->flags & DICT_FLAG_LOCK)
+	&& myflock(dict->lock_fd, INTERNAL_LOCK, MYFLOCK_OP_NONE) < 0)
+	msg_fatal("%s: unlock dictionary: %m", dict->name);
+
     return (status);
 }
 
@@ -685,6 +709,13 @@
     }
 
     /*
+     * Acquire an exclusive lock.
+     */
+    if ((dict->flags & DICT_FLAG_LOCK)
+	&& myflock(dict->lock_fd, INTERNAL_LOCK, MYFLOCK_OP_EXCLUSIVE) < 0)
+	msg_fatal("%s: lock dictionary: %m", dict->name);
+
+    /*
      * See if this LMDB file was written with one null byte appended to key
      * and value.
      */
@@ -723,6 +754,14 @@
 	    dict->flags &= ~DICT_FLAG_TRY1NULL;	/* found */
 	}
     }
+
+    /*
+     * Release the exclusive lock.
+     */
+    if ((dict->flags & DICT_FLAG_LOCK)
+	&& myflock(dict->lock_fd, INTERNAL_LOCK, MYFLOCK_OP_NONE) < 0)
+	msg_fatal("%s: unlock dictionary: %m", dict->name);
+
     return (status);
 }
 
@@ -757,6 +796,13 @@
     }
 
     /*
+     * Acquire a shared lock.
+     */
+    if ((dict->flags & DICT_FLAG_LOCK)
+	&& myflock(dict->lock_fd, INTERNAL_LOCK, MYFLOCK_OP_SHARED) < 0)
+	msg_fatal("%s: lock dictionary: %m", dict->name);
+
+    /*
      * Database lookup.
      */
     status = dict_lmdb_cursor_get(dict_lmdb, &mdb_key, &mdb_value, op);
@@ -792,15 +838,15 @@
 		  dict_lmdb->dict.type, dict_lmdb->dict.name,
 		  mdb_strerror(status));
     }
-    return (status);
-}
 
-/* dict_lmdb_lock - noop lock handler */
+    /*
+     * Release the shared lock.
+     */
+    if ((dict->flags & DICT_FLAG_LOCK)
+	&& myflock(dict->lock_fd, INTERNAL_LOCK, MYFLOCK_OP_NONE) < 0)
+	msg_fatal("%s: unlock dictionary: %m", dict->name);
 
-static int dict_lmdb_lock(DICT *dict, int unused_op)
-{
-    /* LMDB does its own concurrency control */
-    return 0;
+    return (status);
 }
 
 /* dict_lmdb_close - disassociate from data base */
@@ -840,7 +886,7 @@
 
     env_flags = MDB_NOSUBDIR;
     if (open_flags == O_RDONLY)
-	env_flags |= MDB_RDONLY;
+	env_flags |= MDB_RDONLY|MDB_NORDLOCK;
 
     if ((status = mdb_env_create(&env)))
 	msg_fatal("env_create %s: %s", mdb_path, mdb_strerror(status));
@@ -850,9 +896,6 @@
     if ((status = mdb_env_set_mapsize(env, map_size)))
 	msg_fatal("env_set_mapsize %s: %s", mdb_path, mdb_strerror(status));
 
-    if ((status = mdb_env_set_maxreaders(env, dict_lmdb_max_readers)))
-	msg_fatal("env_set_maxreaders %s: %s", mdb_path, mdb_strerror(status));
-
     /*
      * Gracefully handle the most common mistake.
      */
@@ -878,11 +921,11 @@
     dict_lmdb->dict.delete = dict_lmdb_delete;
     dict_lmdb->dict.sequence = dict_lmdb_sequence;
     dict_lmdb->dict.close = dict_lmdb_close;
-    dict_lmdb->dict.lock = dict_lmdb_lock;
     if ((dict_lmdb->dict.stat_fd = open(mdb_path, O_RDONLY)) < 0)
 	msg_fatal("dict_lmdb_open: %s: %m", mdb_path);
     if (fstat(dict_lmdb->dict.stat_fd, &st) < 0)
 	msg_fatal("dict_lmdb_open: fstat: %m");
+    dict_lmdb->dict.lock_fd = dict_lmdb->dict.stat_fd;
     dict_lmdb->dict.mtime = st.st_mtime;
     dict_lmdb->dict.owner.uid = st.st_uid;
     dict_lmdb->dict.owner.status = (st.st_uid != 0);
@@ -918,8 +961,17 @@
     dict_lmdb->env_flags = env_flags;
     dict_lmdb->txn = txn;
     dict_lmdb_prepare(dict_lmdb);
-    if (dict_flags & DICT_FLAG_BULK_UPDATE)
+    if (dict_flags & DICT_FLAG_BULK_UPDATE) {
+    	/* We just need to acquire exclusive access momentarily. This establishes
+	 * that no readers are accessing old txn snapshots, so we are free to reuse
+	 * all eligible old pages. Release the lock right after acquiring it.
+	 */
+    	if (myflock(dict_lmdb->dict.lock_fd, INTERNAL_LOCK, MYFLOCK_OP_EXCLUSIVE) < 0)
+	    msg_fatal("%s: lock dictionary: %m", dict_lmdb->dict.name);
+    	if (myflock(dict_lmdb->dict.lock_fd, INTERNAL_LOCK, MYFLOCK_OP_NONE) < 0)
+	    msg_fatal("%s: unlock dictionary: %m", dict_lmdb->dict.name);
 	dict_jmp_alloc(&dict_lmdb->dict);	/* build into dict_alloc() */
+    }
 
     myfree(mdb_path);
 
